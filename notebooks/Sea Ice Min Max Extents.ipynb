{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "tags": [
     "worksheet-0"
    ]
   },
   "source": [
    "# Compute summary statistics for the daily sea ice index.\n",
    "\n",
    "# From the CSV files determine the day of maximum and minimum extent for each\n",
    "# month and how that month's max and min ranks with all other months\n",
    "\n",
    "The input data format is just a date and extent for each day we have data.\n",
    "```\n",
    "Year, Month, Day,     Extent,    Missing, Source Data\n",
    "YYYY,    MM,  DD, 10^6 sq km, 10^6 sq km, Source data product web site: http://nsidc.org/d....\n",
    "1978,    10,  26,     10.231,      0.000, ftp://sidads.colorado.edu/pub/DATASETS/nsidc0051....\n",
    "1978,    10,  28,     10.420,      0.000, ftp://sidads.colorado.edu/pub/DATASETS/nsidc0051....\n",
    "1978,    10,  30,     10.557,      0.000, ftp://sidads.colorado.edu/pub/DATASETS/nsidc0051....\n",
    "....\n",
    "```\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "tags": [
     "worksheet-0"
    ]
   },
   "source": [
    "Start by downloading the daily sea ice extent data from NSIDC's website."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "metadata": {
    "collapsed": false,
    "tags": [
     "worksheet-0"
    ]
   },
   "outputs": [],
   "source": [
    "!mkdir -p ../data\n",
    "!wget -P ../data -qN ftp://sidads.colorado.edu/pub/DATASETS/NOAA/G02135/north/daily/data/NH_seaice_extent_final.csv \n",
    "!wget -P ../data -qN ftp://sidads.colorado.edu/pub/DATASETS/NOAA/G02135/north/daily/data/NH_seaice_extent_nrt.csv\n",
    "!wget -P ../data -qN ftp://sidads.colorado.edu/pub/DATASETS/NOAA/G02135/south/daily/data/SH_seaice_extent_final.csv\n",
    "!wget -P ../data -qN ftp://sidads.colorado.edu/pub/DATASETS/NOAA/G02135/south/daily/data/SH_seaice_extent_nrt.csv\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "metadata": {
    "collapsed": false,
    "tags": [
     "worksheet-0"
    ]
   },
   "outputs": [],
   "source": [
    "import datetime as dt\n",
    "import numpy as np\n",
    "import os\n",
    "import pandas as pd\n",
    "from pandas import ExcelWriter\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "tags": [
     "worksheet-0"
    ]
   },
   "source": [
    "code to read the CSV files."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "metadata": {
    "collapsed": false,
    "tags": [
     "worksheet-0"
    ]
   },
   "outputs": [],
   "source": [
    "\n",
    "def parse_the_date(year, mm, dd):\n",
    "    return dt.date(int(year), int(mm), int(dd))\n",
    "\n",
    "def slurp_csv(filename):\n",
    "    data = pd.read_csv(filename, header = None, skiprows=2,\n",
    "                       names=[\"year\", \"mm\", \"dd\", \"extent\", \"missing\", \"source\"],\n",
    "                       parse_dates={'date':['year', 'mm', 'dd']},\n",
    "                       date_parser=parse_the_date, index_col='date')\n",
    "    data = data.drop('missing', axis=1)\n",
    "    return data\n",
    "\n",
    "def read_a_hemisphere(hemisphere):\n",
    "    the_dir = '../data'\n",
    "    final_prod_filename = os.path.join(the_dir, '{hemi}H_seaice_extent_final.csv'.format(hemi=hemisphere[0:1].upper()))\n",
    "    nrt_prod_filename = os.path.join(the_dir, '{hemi}H_seaice_extent_nrt.csv'.format(hemi=hemisphere[0:1].upper()))\n",
    "\n",
    "    final = slurp_csv(final_prod_filename)\n",
    "    nrt = slurp_csv(nrt_prod_filename)\n",
    "    all_data = pd.concat([final, nrt])\n",
    "    return all_data\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "tags": [
     "worksheet-0"
    ]
   },
   "source": [
    " Read CSV data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "metadata": {
    "collapsed": false,
    "tags": [
     "worksheet-0"
    ]
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "            extent                                             source\ndate                                                                 \n1978-10-26  17.634   ftp://sidads.colorado.edu/pub/DATASETS/nsidc0...\n1978-10-28  17.815   ftp://sidads.colorado.edu/pub/DATASETS/nsidc0...\n1978-10-30  17.671   ftp://sidads.colorado.edu/pub/DATASETS/nsidc0...\n1978-11-01  17.534   ftp://sidads.colorado.edu/pub/DATASETS/nsidc0...\n1978-11-03  17.493   ftp://sidads.colorado.edu/pub/DATASETS/nsidc0..."
      ]
     },
     "execution_count": 210,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "north = read_a_hemisphere('north')\n",
    "south = read_a_hemisphere('south')\n",
    "south.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "tags": [
     "worksheet-0"
    ]
   },
   "source": [
    "Add columns for year and month: We have do this because when we read the CSV file\n",
    "we converted the existing year/month/day columns into a python datetime object.\n",
    "also drop the source because we don't care where the data came from (near real time or production)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "metadata": {
    "collapsed": false,
    "tags": [
     "worksheet-0"
    ]
   },
   "outputs": [],
   "source": [
    "def add_year_month_columns(df):\n",
    "    a = df.copy()\n",
    "    a = a.drop('source',1)\n",
    "    a = a.reset_index()\n",
    "    a['year'] = pd.to_datetime(a.date).dt.year\n",
    "    a['month'] = pd.to_datetime(a.date).dt.month\n",
    "    a = a.set_index('date')\n",
    "    return a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "metadata": {
    "collapsed": false,
    "tags": [
     "worksheet-0"
    ]
   },
   "outputs": [],
   "source": [
    "north = add_year_month_columns(north)\n",
    "south = add_year_month_columns(south)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "metadata": {
    "collapsed": false,
    "tags": [
     "worksheet-0"
    ]
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "            extent  year  month\ndate                           \n1978-10-26  10.231  1978     10\n1978-10-28  10.420  1978     10\n1978-10-30  10.557  1978     10\n1978-11-01  10.670  1978     11\n1978-11-03  10.787  1978     11"
      ]
     },
     "execution_count": 213,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "north.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "metadata": {
    "collapsed": false,
    "tags": [
     "worksheet-0"
    ]
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "            extent  year  month\ndate                           \n1978-10-26  17.634  1978     10\n1978-10-28  17.815  1978     10\n1978-10-30  17.671  1978     10\n1978-11-01  17.534  1978     11\n1978-11-03  17.493  1978     11"
      ]
     },
     "execution_count": 214,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "south.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "tags": [
     "worksheet-0"
    ]
   },
   "source": [
    "Add 5 day rolling mean to the timesereis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "metadata": {
    "collapsed": false,
    "tags": [
     "worksheet-0"
    ]
   },
   "outputs": [],
   "source": [
    "def add_rolling_mean(df, window=5, min_periods=2):\n",
    "    copy = df.copy()\n",
    "    # create an empty ts to align our extent data with\n",
    "    ts = pd.Series(np.nan, index=pd.date_range('1978-10-25', dt.date.today().strftime('%Y-%m-%d')))\n",
    "    copy.index = copy.index.to_datetime()\n",
    "    copy = df.align(ts, axis=0, join='right')[0]\n",
    "    df['5day-Avg'] = pd.rolling_mean(copy['extent'], window=5, min_periods=2)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "tags": [
     "worksheet-0"
    ]
   },
   "source": [
    "Want date back in the columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "metadata": {
    "collapsed": false,
    "tags": [
     "worksheet-0"
    ]
   },
   "outputs": [],
   "source": [
    "north = add_rolling_mean(north)\n",
    "south = add_rolling_mean(south)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "metadata": {
    "collapsed": false,
    "tags": [
     "worksheet-0"
    ]
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "            extent  year  month  5day-Avg\ndate                                     \n1978-10-26  10.231  1978     10       NaN"
      ]
     },
     "execution_count": 217,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "north.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "metadata": {
    "collapsed": false,
    "tags": [
     "worksheet-0"
    ]
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "         date  extent  year  month  5day-Avg\n0  1978-10-26  10.231  1978     10       NaN"
      ]
     },
     "execution_count": 218,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "north = north.reset_index()\n",
    "south = south.reset_index()\n",
    "north.head(1)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "tags": [
     "worksheet-0"
    ]
   },
   "source": [
    "Use a groupby to compute the row locations that represent the minimum and\n",
    "maximum extent and grab those rows into new variables.  AKA: Filter out everything\n",
    "but the minimum/maximum extent for each month and year"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "metadata": {
    "collapsed": false,
    "tags": [
     "worksheet-0"
    ]
   },
   "outputs": [],
   "source": [
    "def select_min_and_max_variable_rows_by_year_and_month(df, variable):\n",
    "    min_groups = df.loc[df.groupby(['year','month'])[variable].idxmin()][['date', variable, 'year', 'month']]\n",
    "    max_groups = df.loc[df.groupby(['year','month'])[variable].idxmax()][['date', variable, 'year', 'month']]\n",
    "    return {'min': min_groups,  'max': max_groups}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "tags": [
     "worksheet-0"
    ]
   },
   "source": [
    "create dictionaries of max and min values for each hemisphere and for daily and rolling-mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 220,
   "metadata": {
    "collapsed": false,
    "tags": [
     "worksheet-0"
    ]
   },
   "outputs": [],
   "source": [
    "n = select_min_and_max_variable_rows_by_year_and_month(north, 'extent')\n",
    "navg = select_min_and_max_variable_rows_by_year_and_month(north, '5day-Avg')\n",
    "s = select_min_and_max_variable_rows_by_year_and_month(south, 'extent')\n",
    "savg = select_min_and_max_variable_rows_by_year_and_month(south, '5day-Avg')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "tags": [
     "worksheet-0"
    ]
   },
   "source": [
    "show that we have actually selected different data for daily and 5-average data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 221,
   "metadata": {
    "collapsed": false,
    "tags": [
     "worksheet-0"
    ]
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "          date  extent  year  month\n48  1979-01-30  15.912  1979      1\n61  1979-02-25  16.579  1979      2"
      ]
     },
     "execution_count": 221,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n['max'][3:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 222,
   "metadata": {
    "collapsed": false,
    "tags": [
     "worksheet-0"
    ]
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "          date   5day-Avg  year  month\n48  1979-01-30  15.795333  1979      1\n62  1979-02-27  16.515000  1979      2"
      ]
     },
     "execution_count": 222,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "navg['max'][3:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 223,
   "metadata": {
    "collapsed": false,
    "tags": [
     "worksheet-0"
    ]
   },
   "outputs": [],
   "source": [
    "def add_rank(df, rank_by, ascending):\n",
    "    df['rank'] = df.groupby('month')[rank_by].rank(ascending=ascending, method='first')\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "tags": [
     "worksheet-0"
    ]
   },
   "source": [
    "add rank column for each month and hemsiphere's max and min:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 224,
   "metadata": {
    "collapsed": false,
    "tags": [
     "worksheet-0"
    ]
   },
   "outputs": [],
   "source": [
    "n['max'] = add_rank(n['max'], 'extent', ascending=False)\n",
    "n['min'] = add_rank(n['min'], 'extent', ascending=True)\n",
    "s['max'] = add_rank(s['max'], 'extent', ascending=False)\n",
    "s['min'] = add_rank(s['min'], 'extent', ascending=True)\n",
    "\n",
    "navg['max'] = add_rank(navg['max'], '5day-Avg', ascending=False)\n",
    "navg['min'] = add_rank(navg['min'], '5day-Avg', ascending=True)\n",
    "savg['max'] = add_rank(savg['max'], '5day-Avg', ascending=False)\n",
    "savg['min'] = add_rank(savg['min'], '5day-Avg', ascending=True)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 225,
   "metadata": {
    "collapsed": false,
    "tags": [
     "worksheet-0"
    ]
   },
   "outputs": [],
   "source": [
    "def do_annual_min_max_ranking(df, field):\n",
    "    min_index = df.groupby(['year'])[field].idxmin()\n",
    "    max_index = df.groupby(['year'])[field].idxmax()\n",
    "    mindata = df.loc[min_index][['date', field]]\n",
    "    mindata['rank'] = mindata[field].rank(ascending=True, method='first')\n",
    "    maxdata = df.loc[max_index][['date', field]]\n",
    "    maxdata['rank'] = maxdata[field].rank(ascending=False, method='first')\n",
    "\n",
    "    mindata = mindata.set_index(pd.to_datetime(mindata.date).dt.year)\n",
    "    maxdata = maxdata.set_index(pd.to_datetime(maxdata.date).dt.year)\n",
    "\n",
    "    maxdata = maxdata.add_prefix('max_')\n",
    "    mindata = mindata.add_prefix('min_')\n",
    "\n",
    "    data = pd.concat([mindata, maxdata], axis=1)\n",
    "    return data\n",
    "    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "tags": [
     "worksheet-0"
    ]
   },
   "source": [
    "It is also desired that we have Annual min/max rank data so revisit the north and south"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 226,
   "metadata": {
    "collapsed": false,
    "tags": [
     "worksheet-0"
    ]
   },
   "outputs": [],
   "source": [
    "north_annual_by_day = do_annual_min_max_ranking(north, 'extent')\n",
    "north_annual_averaged = do_annual_min_max_ranking(north, '5day-Avg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 227,
   "metadata": {
    "collapsed": false,
    "tags": [
     "worksheet-0"
    ]
   },
   "outputs": [],
   "source": [
    "south_annual_by_day = do_annual_min_max_ranking(south, 'extent')\n",
    "south_annual_averaged = do_annual_min_max_ranking(south, '5day-Avg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 228,
   "metadata": {
    "collapsed": false,
    "tags": [
     "worksheet-0"
    ]
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "        min_date  min_5day-Avg  min_rank    max_date  max_5day-Avg  max_rank\n1978  1978-12-31      7.596000        38  1978-10-28       17.7245        37\n1979  1979-02-19      2.928333        25  1979-09-15       18.3230        31\n1980  1980-02-26      2.574000         7  1980-09-25       19.0470        11"
      ]
     },
     "execution_count": 228,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "south_annual_averaged.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "tags": [
     "worksheet-0"
    ]
   },
   "source": [
    "Write out the data frames in a nice format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 229,
   "metadata": {
    "collapsed": false,
    "tags": [
     "worksheet-0"
    ]
   },
   "outputs": [],
   "source": [
    "a = navg['min'].copy()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 230,
   "metadata": {
    "collapsed": false,
    "tags": [
     "worksheet-0"
    ]
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index([u'date', u'5day-Avg', u'year', u'month', u'rank'], dtype='object')"
      ]
     },
     "execution_count": 230,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 231,
   "metadata": {
    "collapsed": false,
    "tags": [
     "worksheet-0"
    ]
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "             date                                                              \\\nmonth          1           2           3           4           5           6    \nrank                                                                            \n1      2011-01-01  2006-02-01  2006-03-27  2006-04-30  2015-05-31  2010-06-30   \n2      2014-01-01  2011-02-01  2015-03-09  2004-04-30  2006-05-31  2012-06-30   \n3      2013-01-01  2012-02-01  2007-03-31  2007-04-30  2010-05-31  2011-06-30   \n\n                                                       ...   year              \\\nmonth          7           8           9           10  ...     3     4     5    \nrank                                                   ...                      \n1      2012-07-31  2012-08-31  2012-09-17  2012-10-01  ...   2006  2006  2015   \n2      2007-07-31  2007-08-31  2007-09-18  2007-10-01  ...   2015  2004  2006   \n3      2011-07-31  2011-08-31  2011-09-11  2011-10-01  ...   2007  2007  2010   \n\n                                                 \nmonth    6     7     8     9     10    11    12  \nrank                                             \n1      2010  2012  2012  2012  2012  2012  2006  \n2      2012  2007  2007  2007  2007  2007  2010  \n3      2011  2011  2011  2011  2011  2010  2012  \n\n[3 rows x 36 columns]"
      ]
     },
     "execution_count": 231,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a.set_index(['rank', 'month']).unstack('month').head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 232,
   "metadata": {
    "collapsed": false,
    "tags": [
     "worksheet-0"
    ]
   },
   "outputs": [],
   "source": [
    "import calendar\n",
    "month_names = [calendar.month_name[x] for x in range(1,13)]\n",
    "def swap_column_level_and_sort(df):\n",
    "    df.columns = df.columns.swaplevel(1,0)\n",
    "    df = df.sortlevel(0, axis=1)\n",
    "    return df\n",
    "\n",
    "# set index to year and month and then broadcast month back across the columns.\n",
    "# next swap and sort so that you have the data grouped under the month.\n",
    "def prepare_for_csv(df):\n",
    "    df = df.set_index(['rank','month']).unstack('month')\n",
    "    df = swap_column_level_and_sort(df)\n",
    "    df.columns = df.columns.set_levels(month_names, level=0)\n",
    "    return df\n",
    "\n",
    "\n",
    "def write_to_xls(df_list, writer, is_monthly=True):\n",
    "    for df, sheet in df_list:\n",
    "        if is_monthly:\n",
    "            df = prepare_for_csv(df)\n",
    "        df.to_excel(writer,'{sheet}'.format(sheet=sheet), float_format=\"%.3f\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 233,
   "metadata": {
    "collapsed": false,
    "tags": [
     "worksheet-0"
    ]
   },
   "outputs": [],
   "source": [
    "writer = ExcelWriter('../output/Sea_Ice_MinMax_Statistics.xls')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 234,
   "metadata": {
    "collapsed": false,
    "tags": [
     "worksheet-0"
    ]
   },
   "outputs": [],
   "source": [
    "monthly_dataframelist =[(navg['min'], 'Northern 5day Min'),\n",
    "                        (navg['max'], 'Northern 5day Max'),\n",
    "                        (savg['min'], 'Southern 5day Min'),\n",
    "                        (savg['max'], 'Southern 5day Max'),\n",
    "                        (n['min'], 'Northern Daily Min'),\n",
    "                        (n['max'], 'Northern Daily Max'),\n",
    "                        (s['min'], 'Southern Daily Min'),\n",
    "                        (s['max'], 'Southern Daily Max')]\n",
    "annual_dataframelist = [(north_annual_averaged, 'North Annual 5day-avg'),\n",
    "                        (north_annual_by_day, 'North Annual Daily'),\n",
    "                        (south_annual_averaged, 'South Annual 5day-avg'),\n",
    "                        (south_annual_by_day, 'South Annual Daily')]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 235,
   "metadata": {
    "collapsed": false,
    "tags": [
     "worksheet-0"
    ]
   },
   "outputs": [],
   "source": [
    "write_to_xls(monthly_dataframelist, writer, is_monthly=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 236,
   "metadata": {
    "collapsed": false,
    "tags": [
     "worksheet-0"
    ]
   },
   "outputs": [],
   "source": [
    "write_to_xls(annual_dataframelist, writer, is_monthly=False)\n",
    "\n",
    "writer.save()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 237,
   "metadata": {
    "collapsed": false,
    "tags": [
     "worksheet-0"
    ]
   },
   "outputs": [],
   "source": [
    "b = prepare_for_csv(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 238,
   "metadata": {
    "collapsed": false,
    "tags": [
     "worksheet-0"
    ]
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "month     January                     February                        March  \\\n             date   5day-Avg  year        date   5day-Avg  year        date   \nrank                                                                          \n1      2011-01-01  12.595800  2011  2006-02-01  13.894200  2006  2006-03-27   \n2      2014-01-01  12.881600  2014  2011-02-01  14.029800  2011  2015-03-09   \n3      2013-01-01  12.910400  2013  2012-02-01  14.055400  2012  2007-03-31   \n4      2009-01-01  12.994800  2009  2005-02-01  14.069400  2005  2005-03-28   \n5      2015-01-01  13.000800  2015  2010-02-01  14.090400  2010  2011-03-29   \n6      2007-01-01  13.005200  2007  2015-02-01  14.098600  2015  2014-03-31   \n7      2006-01-01  13.031400  2006  2014-02-01  14.174400  2014  2010-03-01   \n8      2008-01-01  13.034200  2008  2007-02-01  14.232600  2007  2004-03-31   \n9      2005-01-01  13.054400  2005  2013-02-01  14.305600  2013  2009-03-13   \n10     2010-01-01  13.102200  2010  2004-02-01  14.343200  2004  2013-03-31   \n11     2012-01-01  13.119800  2012  2009-02-01  14.383400  2009  1996-03-28   \n12     2000-01-01  13.325000  2000  2008-02-01  14.549800  2008  2012-03-01   \n13     2001-01-01  13.368800  2001  1996-02-01  14.637800  1996  2002-03-31   \n14     2004-01-01  13.388000  2004  2001-02-01  14.780400  2001  2008-03-31   \n15     2003-01-01  13.475400  2003  1991-02-01  14.800400  1991  2000-03-23   \n16     2002-01-01  13.476000  2002  1999-02-01  14.830200  1999  1995-03-16   \n17     1991-01-01  13.488600  1991  2003-02-01  14.858000  2003  2001-03-31   \n18     1997-01-01  13.642600  1997  1997-02-01  14.868000  1997  1999-03-06   \n19     1996-01-01  13.690200  1996  1984-02-01  14.918667  1984  1989-03-30   \n20     1999-01-01  13.742600  1999  2000-02-01  14.936800  2000  1991-03-29   \n21     1986-01-01  13.769333  1986  1995-02-01  14.965800  1995  1997-03-31   \n22     1985-01-02  13.795333  1985  2002-02-01  14.995600  2002  2003-03-14   \n23     1993-01-01  13.905600  1993  1990-02-01  15.235800  1990  1998-03-26   \n24     1998-01-01  13.922400  1998  1985-02-03  15.239000  1985  1992-03-07   \n25     1992-01-01  13.922400  1992  1986-02-02  15.249000  1986  1994-03-22   \n26     1984-01-02  13.956000  1984  1992-02-01  15.252000  1992  1984-03-30   \n27     1994-01-01  13.970200  1994  1988-02-11  15.298800  1988  1990-03-31   \n28     1990-01-01  14.022800  1990  1989-02-02  15.371400  1989  1981-03-30   \n29     1995-01-01  14.049800  1995  1994-02-01  15.372800  1994  1988-03-31   \n30     1987-01-02  14.110333  1987  1980-02-02  15.403000  1980  1993-03-01   \n31     1980-01-01  14.151667  1980  1998-02-01  15.408400  1998  1986-03-30   \n32     1989-01-01  14.181600  1989  1981-02-14  15.466000  1981  1985-03-11   \n33     1981-01-01  14.184333  1981  1993-02-02  15.488400  1993  1987-03-27   \n34     1983-01-01  14.186667  1983  1983-02-02  15.657000  1983  1979-03-31   \n35     1982-01-02  14.293000  1982  1987-02-01  15.750333  1987  1980-03-31   \n36     1979-01-02  14.706000  1979  1982-02-01  15.762000  1982  1982-03-27   \n37     1988-01-14  14.840000  1988  1979-02-07  15.833000  1979  1983-03-30   \n\nmonth                        April  ...  September     October             \\\n        5day-Avg  year        date  ...       year        date   5day-Avg   \nrank                                ...                                     \n1      14.229200  2006  2006-04-30  ...       2012  2012-10-01   3.922800   \n2      14.273200  2015  2004-04-30  ...       2007  2007-10-01   4.398200   \n3      14.307000  2007  2007-04-30  ...       2011  2011-10-01   4.928200   \n4      14.418800  2005  2015-04-30  ...       2008  2008-10-01   4.982400   \n5      14.456200  2011  1989-04-30  ...       2010  2010-10-01   5.299400   \n6      14.582200  2014  2014-04-30  ...       2014  2014-10-01   5.494800   \n7      14.838800  2010  2011-04-30  ...       2013  2009-10-01   5.520800   \n8      14.852800  2004  2013-04-30  ...       2009  2013-10-01   5.617800   \n9      14.870000  2009  2005-04-30  ...       2005  2005-10-01   5.625600   \n10     14.901000  2013  2002-04-30  ...       2002  2006-10-01   5.882400   \n11     14.935600  1996  2008-04-30  ...       1999  1995-10-01   6.092600   \n12     14.970600  2012  1996-04-30  ...       2006  2003-10-01   6.246400   \n13     15.020600  2002  1995-04-30  ...       2004  2002-10-01   6.337000   \n14     15.048400  2008  2003-04-30  ...       2000  1990-10-01   6.365600   \n15     15.054000  2000  1990-04-30  ...       1995  2004-10-01   6.448200   \n16     15.151000  1995  2012-04-30  ...       2003  1991-10-01   6.619000   \n17     15.221000  2001  1997-04-30  ...       1990  2000-10-01   6.640400   \n18     15.226200  1999  2009-04-30  ...       1993  1999-10-01   6.869800   \n19     15.266600  1989  2010-04-30  ...       1991  1998-10-01   6.874600   \n20     15.296600  1991  2000-04-30  ...       1998  1997-10-01   6.879800   \n21     15.300600  1997  1992-04-30  ...       1984  1993-10-01   7.014400   \n22     15.320400  2003  1991-04-30  ...       1985  2001-10-01   7.029600   \n23     15.380400  1998  1998-04-30  ...       2001  1985-10-01   7.156333   \n24     15.411000  1992  2001-04-30  ...       1997  1979-10-01   7.234667   \n25     15.419600  1994  1993-04-30  ...       1989  1989-10-01   7.285000   \n26     15.478667  1984  1983-04-29  ...       1981  1984-10-02   7.583000   \n27     15.515800  1990  1994-04-30  ...       1979  1994-10-01   7.615000   \n28     15.541333  1981  1984-04-29  ...       1994  1982-10-01   7.643000   \n29     15.617600  1988  1988-04-30  ...       1987  1981-10-02   7.700667   \n30     15.630800  1993  1999-04-30  ...       1988  1987-10-01   7.795400   \n31     15.633667  1986  1986-04-29  ...       1986  1988-10-01   7.871200   \n32     15.634667  1985  1981-04-29  ...       1982  1983-10-02   7.917667   \n33     15.746667  1987  1987-04-30  ...       1996  1986-10-02   8.028333   \n34     15.889000  1979  1980-04-30  ...       1992  1980-10-01   8.069333   \n35     15.896667  1980  1985-04-30  ...       1983  1992-10-01   8.146600   \n36     15.900667  1982  1979-04-30  ...       1980  1996-10-01   8.197400   \n37     15.913000  1983  1982-04-30  ...        NaN  1978-10-28  10.325500   \n\nmonth          November                     December                   \n       year        date   5day-Avg  year        date   5day-Avg  year  \nrank                                                                   \n1      2012  2012-11-01   7.787000  2012  2006-12-01  10.152800  2006  \n2      2007  2007-11-01   8.194800  2007  2010-12-01  10.458200  2010  \n3      2011  2010-11-01   8.243200  2010  2012-12-01  10.642000  2012  \n4      2008  2011-11-01   8.414600  2011  2007-12-01  10.757200  2007  \n5      2010  2009-11-01   8.505200  2009  2011-12-01  10.786600  2011  \n6      2014  2013-11-01   8.887400  2013  2009-12-01  10.916200  2009  \n7      2009  2006-11-01   8.942200  2006  2014-12-01  11.084000  2014  \n8      2013  2014-11-01   8.957200  2014  2013-12-01  11.089200  2013  \n9      2005  2004-11-01   9.011200  2004  2003-12-01  11.112200  2003  \n10     2006  2003-11-01   9.158400  2003  2005-12-01  11.137200  2005  \n11     1995  2005-11-01   9.187000  2005  2008-12-01  11.212200  2008  \n12     2003  2002-11-01   9.191200  2002  2001-12-01  11.218800  2001  \n13     2002  2008-11-01   9.194400  2008  2000-12-01  11.295400  2000  \n14     1990  1998-11-01   9.324600  1998  1998-12-01  11.318400  1998  \n15     2004  2001-11-01   9.377800  2001  2004-12-01  11.341600  2004  \n16     1991  2000-11-01   9.435400  2000  1996-12-01  11.359200  1996  \n17     2000  1984-11-01   9.465333  1984  1999-12-01  11.441400  1999  \n18     1999  1997-11-01   9.583000  1997  2002-12-01  11.525800  2002  \n19     1998  1991-11-01   9.687400  1991  1991-12-01  11.780000  1991  \n20     1997  1981-11-01   9.744333  1981  1981-12-01  11.858333  1981  \n21     1993  1996-11-01   9.761600  1996  1997-12-01  11.877000  1997  \n22     2001  1999-11-01   9.839200  1999  1995-12-01  11.901000  1995  \n23     1985  1995-11-01   9.851200  1995  1984-12-01  11.913333  1984  \n24     1979  1987-11-01   9.862800  1987  1985-12-02  12.002667  1985  \n25     1989  1985-11-02   9.878667  1985  1990-12-01  12.014200  1990  \n26     1984  1979-11-02   9.955000  1979  1994-12-01  12.070400  1994  \n27     1994  1990-11-01   9.959200  1990  1979-12-02  12.116667  1979  \n28     1982  1988-11-01   9.968000  1988  1993-12-01  12.118000  1993  \n29     1981  1993-11-01  10.011600  1993  1987-12-01  12.225400  1987  \n30     1987  1989-11-01  10.075600  1989  1986-12-01  12.362333  1986  \n31     1988  1994-11-01  10.131000  1994  1989-12-01  12.408600  1989  \n32     1983  1992-11-01  10.133200  1992  1983-12-01  12.438000  1983  \n33     1986  1980-11-02  10.176333  1980  1988-12-01  12.443800  1988  \n34     1980  1986-11-01  10.305333  1986  1992-12-01  12.499000  1992  \n35     1992  1983-11-01  10.374000  1983  1980-12-02  12.589667  1980  \n36     1996  1978-11-01  10.549000  1978  1982-12-02  12.666667  1982  \n37     1978  1982-11-02  10.665333  1982  1978-12-03  12.693000  1978  \n\n[37 rows x 36 columns]"
      ]
     },
     "execution_count": 238,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "b"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "tags": [
     "worksheet-0"
    ]
   },
   "source": [
    "clean up your csv files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 239,
   "metadata": {
    "collapsed": false,
    "tags": [
     "worksheet-0"
    ]
   },
   "outputs": [],
   "source": [
    "!cd ../data ; rm -f NH_seaice_extent_final.csv NH_seaice_extent_nrt.csv SH_seaice_extent_final.csv SH_seaice_extent_nrt.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 239,
   "metadata": {
    "collapsed": false,
    "tags": [
     "worksheet-0"
    ]
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.9"
  },
  "name": "Sea Ice Min Max Extents.ipynb"
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
