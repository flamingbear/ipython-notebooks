{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "##### Guided tour on how the daily 5-day statistics work with pandas"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "As always first fetch the nsidc daily sea ice concentration data to our output directory."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "!wget -P ../output -qN ftp://sidads.colorado.edu/pub/DATASETS/NOAA/G02135/north/daily/data/NH_seaice_extent_final.csv\n",
    "!wget -P ../output -qN ftp://sidads.colorado.edu/pub/DATASETS/NOAA/G02135/north/daily/data/NH_seaice_extent_nrt.csv\n",
    "!wget -P ../output -qN ftp://sidads.colorado.edu/pub/DATASETS/NOAA/G02135/south/daily/data/SH_seaice_extent_final.csv\n",
    "!wget -P ../output -qN ftp://sidads.colorado.edu/pub/DATASETS/NOAA/G02135/south/daily/data/SH_seaice_extent_nrt.csv\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "Variables to set before running:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "hemisphere = 'north'  # 'south' or 'north'\n",
    "climatology_years = (1981, 2010)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# some imports for working with pandas, and excel files.\n",
    "import datetime as dt\n",
    "import numpy as np\n",
    "\n",
    "import os\n",
    "import pandas as pd\n",
    "from pandas import ExcelWriter\n",
    "\n",
    "%matplotlib inline\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "pd.options.display.mpl_style = 'default'\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# code for reading a hemisphere of data from CSV files.\n",
    "\n",
    "def parse_the_date(year, mm, dd):\n",
    "    return dt.date(int(year), int(mm), int(dd))\n",
    "\n",
    "def slurp_csv(filename):\n",
    "    data = pd.read_csv(filename, header = None, skiprows=2,\n",
    "                       names=[\"year\", \"mm\", \"dd\", \"extent\", \"missing\", \"source\"],\n",
    "                       parse_dates={'date':['year', 'mm', 'dd']},\n",
    "                       date_parser=parse_the_date, index_col='date')\n",
    "    data = data.drop(['missing', 'source'], axis=1)\n",
    "    return data\n",
    "\n",
    "\n",
    "def read_a_hemisphere(hemisphere):\n",
    "    the_dir = \"../output\"\n",
    "    final_prod_filename = os.path.join(the_dir, '{hemi}H_seaice_extent_final.csv'.format(hemi=hemisphere[0:1].upper()))\n",
    "    nrt_prod_filename = os.path.join(the_dir, '{hemi}H_seaice_extent_nrt.csv'.format(hemi=hemisphere[0:1].upper()))\n",
    "\n",
    "    final = slurp_csv(final_prod_filename)\n",
    "    nrt = slurp_csv(nrt_prod_filename)\n",
    "    all_data = pd.concat([final, nrt])\n",
    "    return all_data\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df = read_a_hemisphere(hemisphere)\n",
    "\n",
    "# df.head(3) => just shows 3 rows from your dataframe\n",
    "df.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "Set date index to a special DatetimeIndex and then Reindex the dataframe so\n",
    "that every daily timestep is included in the series and any missing data is\n",
    "marked as NaN."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# index before turning into DatetimeIndex\n",
    "print df.index[0:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df.index = pd.to_datetime(df.index)\n",
    "df  = df.reindex(index=pd.date_range('1978-10-25', dt.date.today().strftime('%Y-%m-%d')))\n",
    "df['hemi'] = hemisphere\n",
    "print( df.head())\n",
    "print(\"\\nindex: \")\n",
    "print( df.index)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## interpolate missing data in SMMR period.\n",
    "\n",
    "We don't want to interpolate across any timeperiods where more than one day\n",
    "of data is missing, but we do want to do a strict linear interpolation across\n",
    "the standard every-other-day that SMMR operated.\n",
    "\n",
    "So we are going to do both a forward and backwards fill on the extent field,\n",
    "while setting the limit of missing values to one.  Next, we are going to\n",
    "union the NaNs that remain after the fills in order to leave any gaps in the\n",
    "data record alone when we perform an interpolation.\n",
    "\n",
    "So start by using the backfill to fill any NaN locations that have a valid \"next\" value.\n",
    "So start by using the forwardfill to fill any NaN locations that have a valid \"previous\" value."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df['backfill'] = df.extent.fillna(method='bfill', limit=1)\n",
    "df['forwardfill'] = df.extent.fillna(method='ffill', limit=1)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "See below that in the backfill column, 1978-10-25 was filled with the value\n",
    "(10.231) from 1978-10-26 and that in the forwardfill column, the value\n",
    "remains NaN, but that in the forwardfill column, 1978-10-27 value gets the\n",
    "extent from 1978-10-26"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print(df.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "See that 1987-12-03 gets a forward, but not a backfill"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print(df['19871201':'19871206'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "See that 1988-01-12 gets a backfill, but not a forwardfill"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print(df['19880110':'19880114'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "So the union of backfill's NaN and forward fill NaN will capture any missing\n",
    "data that doesn't have a valid data point both before and after itself in the series.\n",
    "We can get a list of is really NAN by saving this off."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "is_really_nan = pd.isnull(df['backfill']) | pd.isnull(df['forwardfill'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "1. Use the interpolation scheme to do simple linear regression on the entire extent column\n",
    "2. Then go back and mark as missing any large gaps in the linearly interpolated data.\n",
    "3. Drop the backfill and forwardfill columns\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df['interpolated'] = df.extent.interpolate()\n",
    "#df['interpolated'].loc[is_really_nan] = np.nan\n",
    "df.interpolated.loc[is_really_nan == True] = np.nan\n",
    "df = df.drop(['forwardfill', 'backfill'], axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "So now we have a simple dataframe with daily extents and daily interpolated extents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### Add 5 day rolling mean from the interpolated data to the extent."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df['5 Day'] = pd.rolling_mean(df['interpolated'], window=5, min_periods=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Compute climatological means by selecting a copy of the data between your desired climatology years."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "clim_data = df[(df.index.year >= climatology_years[0])&(df.index.year <= climatology_years[1] )].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print clim_data.head(3),\"\\n...\\n\" ,clim_data.tail(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "show the years of the climatology and then number of years to work with."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print len(np.unique(clim_data.index.year))\n",
    "print np.unique(clim_data.index.year)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "grab the mean value of the interpolated extents for each month/day combination"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def clim_string(climatology_years):\n",
    "    return  '{0}-{1}'.format(climatology_years[0], climatology_years[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def get_climatological_means(column, clim_data):\n",
    "    means = clim_data.copy()\n",
    "    means = means.groupby([clim_data.index.month, clim_data.index.day]).mean()[[column]]\n",
    "    means = means.rename(columns={column: clim_string(climatology_years)})\n",
    "    return means"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "daily_means = get_climatological_means('interpolated', clim_data)\n",
    "five_day_means = get_climatological_means('5 Day', clim_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print five_day_means.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "**check yourself**:  You can see in the three panels below that the value we get by calling\n",
    "`mean()` on the `groupby` result is the same as expected by averaging the day\n",
    "and month data separately"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "testmeans = clim_data.groupby([clim_data.index.month, clim_data.index.day]).mean()[['interpolated']]\n",
    "testmeans.head(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "Select the January 1 data for climatology_years"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "clim_data[(clim_data.index.month == 1)&(clim_data.index.day == 1)]['interpolated'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "np.nanmean(clim_data[(clim_data.index.month == 1)&(clim_data.index.day == 1)]['interpolated'].values)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "##### Get the daily extent data into the correct format for display and for concatenating with the clim_averages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df.index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import calendar\n",
    "month_names = [calendar.month_name[x] for x in range(1,13)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "right now the data is all stored a timeseries with an index of datetimes and\n",
    "columns of extent, interpolated-extent, and 5 day rolling mean extents.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df.head(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "So we would like to reorder (pivot) the data into a nice dataframe where\n",
    "Months/Days are shown along the left side, and years are columns across and a\n",
    "datavalue is displayed as the \"meat\"\n",
    "            1979  1980\n",
    "     Jan 1  data  data ...\n",
    "         2  data  data\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "There are a couple of ways to do this:\n",
    "You can select a column, or columns and set the index to by a hierarchy of year/month/day, and then unstack the year."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df= df[['extent']].set_index([df.index.year, df.index.month, df.index.day]).unstack(0)\n",
    "df.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "We now want to concat the climatology means on to this newly shaped dataframe.\n",
    "But before you can do that the column indices must match."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print df.columns.nlevels\n",
    "print df.columns.levels\n",
    "print daily_means.columns.nlevels"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "so drop the extra extent level"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df.columns = df.columns.droplevel(0)\n",
    "print df.columns.nlevels"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "Now concatinate and the dataframe is ready to be output."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df = pd.concat([df, daily_means.copy()], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df.to_csv('test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# cleanup\n",
    "!cd ../output; rm -f NH_seaice_extent_final.csv NH_seaice_extent_nrt.csv SH_seaice_extent_final.csv SH_seaice_extent_nrt.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.9"
  },
  "name": "Describe Daily CSV and 5-day Sea Ice statistics.ipynb"
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
