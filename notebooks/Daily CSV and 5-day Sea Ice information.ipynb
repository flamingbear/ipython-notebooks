{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "Reformat and do 5-day averaging on daily sea ice data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 947,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "!wget -qN ftp://sidads.colorado.edu/pub/DATASETS/NOAA/G02135/north/daily/data/NH_seaice_extent_final.csv\n",
    "!wget -qN ftp://sidads.colorado.edu/pub/DATASETS/NOAA/G02135/north/daily/data/NH_seaice_extent_nrt.csv\n",
    "!wget -qN ftp://sidads.colorado.edu/pub/DATASETS/NOAA/G02135/south/daily/data/SH_seaice_extent_final.csv\n",
    "!wget -qN ftp://sidads.colorado.edu/pub/DATASETS/NOAA/G02135/south/daily/data/SH_seaice_extent_nrt.csv\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "Variables to set before running:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 948,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "hemisphere = 'north'  # 'south'\n",
    "climatology_years = (1981, 2010)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 949,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import datetime as dt\n",
    "import numpy as np\n",
    "\n",
    "import os\n",
    "import pandas as pd\n",
    "from pandas import ExcelWriter\n",
    "%matplotlib inline\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "pd.options.display.mpl_style = 'default'\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 950,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\n",
    "def parse_the_date(year, mm, dd):\n",
    "    return dt.date(int(year), int(mm), int(dd))\n",
    "\n",
    "def slurp_csv(filename):\n",
    "    data = pd.read_csv(filename, header = None, skiprows=2,\n",
    "                       names=[\"year\", \"mm\", \"dd\", \"extent\", \"missing\", \"source\"],\n",
    "                       parse_dates={'date':['year', 'mm', 'dd']},\n",
    "                       date_parser=parse_the_date, index_col='date')\n",
    "    data = data.drop(['missing', 'source'], axis=1)\n",
    "    return data\n",
    "\n",
    "\n",
    "def read_a_hemisphere(hemisphere):\n",
    "    final_prod_filename = os.path.join('{hemi}H_seaice_extent_final.csv'.format(hemi=hemisphere[0:1].upper()))\n",
    "    nrt_prod_filename = os.path.join('{hemi}H_seaice_extent_nrt.csv'.format(hemi=hemisphere[0:1].upper()))\n",
    "\n",
    "    final = slurp_csv(final_prod_filename)\n",
    "    nrt = slurp_csv(nrt_prod_filename)\n",
    "    all_data = pd.concat([final, nrt])\n",
    "    return all_data\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 951,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "            extent\ndate              \n1978-10-26  10.231\n1978-10-28  10.420\n1978-10-30  10.557"
      ]
     },
     "execution_count": 951,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = read_a_hemisphere(hemisphere)\n",
    "df.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "Set indices to datetime indexes and reindex so that every daily timestep is included in the series."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 952,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "            extent   hemi\n1978-10-25     NaN  north\n1978-10-26  10.231  north\n1978-10-27     NaN  north\n1978-10-28  10.420  north\n1978-10-29     NaN  north"
      ]
     },
     "execution_count": 952,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.index = pd.to_datetime(df.index)\n",
    "df  = df.reindex(index=pd.date_range('1978-10-25', dt.date.today().strftime('%Y-%m-%d')))\n",
    "df['hemi'] = hemisphere\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## interpolate missing data in SMMR period.\n",
    "\n",
    "We don't want to interpolate across any timeperiods where more than one day\n",
    "of data is missing.  So we are going to union the NaN that remain after a\n",
    "back fill and forward fill in order to leave any gaps in the data record\n",
    "alone.\n",
    "\n",
    "So start by using the backfill to fill any NaN locations that have a valid \"next\" value.\n",
    "So start by using the forwardfill to fill any NaN locations that have a valid \"previous\" value."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 953,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df['backfill'] = df.extent.fillna(method='bfill', limit=1)\n",
    "df['forwardfill'] = df.extent.fillna(method='ffill', limit=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 954,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "            extent   hemi  backfill  forwardfill\n1978-10-25     NaN  north    10.231          NaN\n1978-10-26  10.231  north    10.231       10.231\n1978-10-27     NaN  north    10.420       10.231\n1978-10-28  10.420  north    10.420       10.420\n1978-10-29     NaN  north    10.557       10.420"
      ]
     },
     "execution_count": 954,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 955,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "            extent   hemi  backfill  forwardfill\n1987-12-01  12.504  north    12.504       12.504\n1987-12-02  12.600  north    12.600       12.600\n1987-12-03     NaN  north       NaN       12.600\n1987-12-04     NaN  north       NaN          NaN\n1987-12-05     NaN  north       NaN          NaN\n1987-12-06     NaN  north       NaN          NaN"
      ]
     },
     "execution_count": 955,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['19871201':'19871206']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 956,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "            extent   hemi  backfill  forwardfill\n1988-01-10     NaN  north       NaN          NaN\n1988-01-11     NaN  north       NaN          NaN\n1988-01-12     NaN  north    14.826          NaN\n1988-01-13  14.826  north    14.826       14.826\n1988-01-14  14.854  north    14.854       14.854"
      ]
     },
     "execution_count": 956,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['19880110':'19880114']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "So the union of backfill's NaN and forward fill NaN will capture any missing\n",
    "data that doesn't have a valid data point both before and after itself in the series.\n",
    "We can get a list of is really NAN by saving this off."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 957,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "is_really_nan = pd.isnull(df['backfill']) | pd.isnull(df['forwardfill'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "Use the interpolation scheme to do simple linear regression on all data and then\n",
    "Mark missing any large gaps in the linearly interpolated data and drop the backfill and forwardfill columns\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 958,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df['interpolated'] = df.extent.interpolate()\n",
    "df[is_really_nan].interpolated = np.nan\n",
    "df.drop(['forwardfill', 'backfill'], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "So now we have a simple dataframe with daily extents and daily interpolated extents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 959,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "            extent   hemi  interpolated\n1978-10-25     NaN  north           NaN\n1978-10-26  10.231  north       10.2310\n1978-10-27     NaN  north       10.3255\n1978-10-28  10.420  north       10.4200\n1978-10-29     NaN  north       10.4885"
      ]
     },
     "execution_count": 959,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "##Compute climatological means by working with just the data between your desired climatology years."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 960,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "clim_data = df[(df.index.year >= climatology_years[0])&(df.index.year <= climatology_years[1] )].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 961,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "            extent   hemi  interpolated\n",
      "1981-01-01  14.288  north       14.2880\n",
      "1981-01-02     NaN  north       14.3955\n",
      "1981-01-03  14.503  north       14.5030\n",
      "1981-01-04     NaN  north       14.4810\n",
      "1981-01-05  14.459  north       14.4590 \n",
      "...\n",
      "            extent   hemi  interpolated\n",
      "2010-12-27  12.358  north        12.358\n",
      "2010-12-28  12.398  north        12.398\n",
      "2010-12-29  12.457  north        12.457\n",
      "2010-12-30  12.558  north        12.558\n",
      "2010-12-31  12.670  north        12.670\n"
     ]
    }
   ],
   "source": [
    "print clim_data.head(),\"\\n...\\n\" ,clim_data.tail()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "show the years of the climatology and then number of years to work with."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 962,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "30\n",
      "[1981 1982 1983 1984 1985 1986 1987 1988 1989 1990 1991 1992 1993 1994 1995\n",
      " 1996 1997 1998 1999 2000 2001 2002 2003 2004 2005 2006 2007 2008 2009 2010]\n"
     ]
    }
   ],
   "source": [
    "print len(np.unique(clim_data.index.year))\n",
    "print np.unique(clim_data.index.year)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "grab the mean value of the interpolated extents for each month/day combination"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 963,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "clim_averages = clim_data.groupby([clim_data.index.month, clim_data.index.day]).mean()[['interpolated']]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "**check yourself**:  You can see in the three panels below that the value we get by calling\n",
    "`mean()` on the `groupby` result is the same as expected by averaging the day\n",
    "and month data separately"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 964,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 14.288 ,  14.371 ,  14.257 ,  14.0065,  13.946 ,  14.036 ,\n        14.197 ,  14.19  ,  14.261 ,  14.319 ,  13.634 ,  14.069 ,\n        14.039 ,  14.094 ,  14.144 ,  13.804 ,  13.657 ,  14.025 ,\n        13.823 ,  13.442 ,  13.479 ,  13.59  ,  13.647 ,  13.502 ,\n        13.16  ,  13.16  ,  13.11  ,  13.206 ,  13.189 ,  13.205 ])"
      ]
     },
     "execution_count": 964,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clim_data[(clim_data.index.month == 1)&(clim_data.index.day == 1)]['interpolated'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 965,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "13.795016666666671"
      ]
     },
     "execution_count": 965,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean(clim_data[(clim_data.index.month == 1)&(clim_data.index.day == 1)]['interpolated'].values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 966,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "     interpolated\n1 1     13.795017"
      ]
     },
     "execution_count": 966,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clim_averages.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 967,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "     1981-2010\n1 1  13.795017"
      ]
     },
     "execution_count": 967,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clim_averages = clim_averages.rename(columns={'interpolated': '1981-2010'})\n",
    "clim_averages.head(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "####Set the daily extent data into the correct format for display and for concatenating with the clim_averages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 968,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<class 'pandas.tseries.index.DatetimeIndex'>\n[1978-10-25, ..., 2015-05-05]\nLength: 13342, Freq: D, Timezone: None"
      ]
     },
     "execution_count": 968,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 969,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df = df[['extent']].set_index([df.index.year, df.index.month, df.index.day]).unstack(0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 970,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MultiIndex(levels=[[1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12], [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31]],\n           labels=[[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 3, ...], [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 0, 1, 2, 3, 4, 5, 6, 7, 8, ...]])"
      ]
     },
     "execution_count": 970,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.index"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "remove the extraneous 'extent' level on the columns so we can concat. (turn into a simple index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 971,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df.columns = df.columns.droplevel(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "add a spacer on the output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 972,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "space = clim_averages.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 973,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "space['1981-2010'] = \"    \"\n",
    "space.rename(columns={'1981-2010': '   '}, inplace=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 974,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "daily_extent_with_climatological_average = pd.concat([df,space, clim_averages], axis=1)\n",
    "\n",
    "r = daily_extent_with_climatological_average"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "Add back a toplevel multi-index column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 975,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index([1978, 1979, 1980, 1981, 1982, 1983, 1984, 1985, 1986, 1987, 1988, 1989, 1990, 1991, 1992, 1993, 1994, 1995, 1996, 1997, 1998, 1999, 2000, 2001, 2002, 2003, 2004, 2005, 2006, 2007, 2008, 2009, 2010, 2011, 2012, 2013, 2014, 2015, u'   ', u'1981-2010'], dtype='object')"
      ]
     },
     "execution_count": 975,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "r.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 976,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "r['extent'] = 'Daily Extents : with climatological means based on interpolated data'\n",
    "r.set_index('extent', append=True, inplace=True)\n",
    "r = r.unstack('extent')\n",
    "r.columns =r.columns.reorder_levels(['extent', None])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 977,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import calendar\n",
    "month_names = [calendar.month_name[x] for x in range(1,13)]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 978,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MultiIndex(levels=[[u'Daily Extents : with climatological means based on interpolated data'], [1978, 1979, 1980, 1981, 1982, 1983, 1984, 1985, 1986, 1987, 1988, 1989, 1990, 1991, 1992, 1993, 1994, 1995, 1996, 1997, 1998, 1999, 2000, 2001, 2002, 2003, 2004, 2005, 2006, 2007, 2008, 2009, 2010, 2011, 2012, 2013, 2014, 2015, u'   ', u'1981-2010']],\n           labels=[[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39]],\n           names=[u'extent', None])"
      ]
     },
     "execution_count": 978,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "r.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 979,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "writer = ExcelWriter('../output/test_daily.xls')\n",
    "r.to_excel(writer, float_format = \"%.3f\")\n",
    "writer.save()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 980,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# cleanup\n",
    "!rm -f NH_seaice_extent_final.csv NH_seaice_extent_nrt.csv SH_seaice_extent_final.csv SH_seaice_extent_nrt.csv\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 980,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.9"
  },
  "name": "Daily CSV and 5-day Sea Ice information.ipynb"
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
